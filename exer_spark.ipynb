{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark=SparkSession.builder.appName('exer_spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Average Friends by Age ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,Will,33,385',\n",
       " '1,Jean-Luc,26,2',\n",
       " '2,Hugh,55,221',\n",
       " '3,Deanna,40,465',\n",
       " '4,Quark,68,21']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data=sc.textFile('file:///D:\\\\data\\\\fakefriends.csv')\n",
    "f_data.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_numf=f_data.map(lambda x:(x.split(',')[2],x.split(',')[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('33', ('385', 1)),\n",
       " ('26', ('2', 1)),\n",
       " ('55', ('221', 1)),\n",
       " ('40', ('465', 1)),\n",
       " ('68', ('21', 1))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_num_map=age_numf.mapValues(lambda x: (x,1))\n",
    "age_num_map.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('33', ('38574471275245356460294243463228410', 12)),\n",
       " ('26', ('228184282381145345293298492269254738312439184', 17)),\n",
       " ('40', ('4652544594071828438934940619817233567261286220', 17)),\n",
       " ('68', ('21264112490481217189206293423', 10)),\n",
       " ('54', ('30725375440744123536939746272442115', 13))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_totalnum=age_num_map.reduceByKey(lambda x,y: (x[0] + y[0], x[1] + y[1]))\n",
    "age_totalnum.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('33', 3.214539272937113e+33),\n",
       " ('26', 1.3422604845949725e+43),\n",
       " ('40', 2.736790937689311e+44),\n",
       " ('68', 2.1264112490481217e+27),\n",
       " ('54', 2.3634904185187785e+33)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_age=age_totalnum.mapValues(lambda x:float(x[0])/x[1])\n",
    "\n",
    "average_age.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wordcount of a text file with regex ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=sc.textFile('file:///D:\\\\data\\\\Book.txt')\n",
    "#words=lines.flatMap(lambda x:x.split())\n",
    "#words.take(10) # there are many special characters and blanks (seen thru collect()),so we need to use regex to ensure only valid words are selected\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def regex_pr(line): # to filter special characters\n",
    "    c=re.compile(r'\\W+',re.UNICODE)\n",
    "    return c.split(line.lower())  # after compiling regexp for detecting valid chars apply that to \n",
    "                                  # split line where capitals and smalls are treated equal. \n",
    "    #return re.split(c,line.lower())\n",
    "    #re.split(<pattern,<text>) expects a text s argument.\n",
    "    #re.compile(<pattern>,<flag>) and saving the resulting regular expression object for reuse is more efficient\n",
    "    #when the expression will be used several times in a single program\n",
    "    # re.UNICODE to specify the text has some unicode info . you can also write it as re.U.\n",
    " \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['self',\n",
       " 'employment',\n",
       " 'building',\n",
       " 'an',\n",
       " 'internet',\n",
       " 'business',\n",
       " 'of',\n",
       " 'one',\n",
       " 'achieving',\n",
       " 'financial']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=lines.flatMap(regex_pr)  \n",
    "words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('self', 111), ('an', 178), ('internet', 26), ('business', 383), ('of', 970)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_of_words=words.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y)\n",
    "count_of_words.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('self', 111)\n",
      "('an', 178)\n",
      "('internet', 26)\n",
      "('business', 383)\n",
      "('of', 970)\n"
     ]
    }
   ],
   "source": [
    "for c in count_of_words.take(5): # printing count of words\n",
    "    print(c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1878, 'you')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_by_count=count_of_words.map(lambda x :(x[1],x[0])).sortByKey(False)\n",
    "sort_by_count.first() # max count and related word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self:111\n",
      "an:178\n",
      "internet:26\n",
      "business:383\n",
      "of:970\n"
     ]
    }
   ],
   "source": [
    "for c in count_of_words.take(5): # formating result as word:count\n",
    "    count = str(c[1])\n",
    "    word = str(c[0])\n",
    "    print(word+':'+count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Most Popular Superhero and coappearances in a Social Graph ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseNames(line):\n",
    "    fields = line.split('\\\"') #split on quotes to get key and name\n",
    "    return (int(fields[0]), fields[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countCoOccurences(line):\n",
    "    #elements = line.strip().split()\n",
    "    elements = line.split()\n",
    "    return (int(elements[0]), len(elements) -1) # to subtract id (key) from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 \"24-HOUR MAN/EMMANUEL\"',\n",
       " '2 \"3-D MAN/CHARLES CHAN\"',\n",
       " '3 \"4-D MAN/MERCURIO\"',\n",
       " '4 \"8-BALL/\"',\n",
       " '5 \"A\"']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = sc.textFile(\"file:///D:\\\\data\\\\marvel-names.txt\")\n",
    "names.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '24-HOUR MAN/EMMANUEL'),\n",
       " (2, '3-D MAN/CHARLES CHAN'),\n",
       " (3, '4-D MAN/MERCURIO'),\n",
       " (4, '8-BALL/'),\n",
       " (5, 'A'),\n",
       " (6, \"A'YIN\"),\n",
       " (7, 'ABBOTT, JACK'),\n",
       " (8, 'ABCISSA'),\n",
       " (9, 'ABEL'),\n",
       " (10, 'ABOMINATION/EMIL BLO')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namesRdd = names.map(parseNames)\n",
    "namesRdd.take(10) # contains key of superhero,name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5988 748 1722 3752 4655 5743 1872 3413 5527 6368 6085 4319 4728 1636 2397 3364 4001 1614 1819 1585 732 2660 3952 2507 3891 2070 2239 2602 612 1352 5447 4548 1596 5488 1605 5517 11 479 2554 2043 17 865 4292 6312 473 534 1479 6375 4456 ',\n",
       " '5989 4080 4264 4446 3779 2430 2297 6169 3530 3272 4282 6432 2548 4140 185 105 3878 2429 1334 4595 2767 3956 3877 4776 4946 3407 128 269 5775 5121 481 5516 4758 4053 1044 1602 3889 1535 6038 533 3986 ',\n",
       " '5982 217 595 1194 3308 2940 1815 794 1503 5197 859 5096 6039 2664 651 2244 528 284 1449 1097 1172 1092 108 3405 5204 387 4607 4545 3705 4930 1805 4712 4404 247 4754 4427 1845 536 5795 5978 533 3984 6056 ',\n",
       " '5983 1165 3836 4361 1282 716 4289 4646 6300 5084 2397 4454 1913 5861 5485 ',\n",
       " '5980 2731 3712 1587 6084 2472 2546 6313 875 859 323 2664 1469 522 2506 2919 2423 3624 5736 5046 1787 5776 3245 3840 2399 ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"file:///D:\\\\data\\\\marvel-graph.txt\")\n",
    "lines.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5988, 48),\n",
       " (5989, 40),\n",
       " (5982, 42),\n",
       " (5983, 14),\n",
       " (5980, 24),\n",
       " (5981, 17),\n",
       " (5986, 142),\n",
       " (5987, 81),\n",
       " (5984, 41),\n",
       " (5985, 19)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairings = lines.map(countCoOccurences)\n",
    "pairings.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFriendsByCharacter = pairings.reduceByKey(lambda x, y : x + y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(859, 1933)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostpopular=totalFriendsByCharacter.sortBy(lambda x:x[1],False).first() #sort value for each key in descending order\n",
    "mostpopular #key of superhero,occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1933, 859)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternate way of finding max value of key is using max()\n",
    "\n",
    "flipped = totalFriendsByCharacter.map(lambda x : (x[1],x[0]))\n",
    "flipped.take(10)\n",
    "mostpopular1=flipped.max() # max number of coappearances ,max() operate on key of k,v pair or max(<key function>) where key can be changed\n",
    "mostpopular1 #contains count of friends,key of superhero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popular name is CAPTAIN AMERICA with coappearances=1933\n"
     ]
    }
   ],
   "source": [
    "# to get matching name from id (key\n",
    "\n",
    "#for name in namesRdd.collect():\n",
    "    #if mostpopular1[1]==name[0]: # mostpopular[0]==name[0]:\n",
    "       #print(name[1])\n",
    "        \n",
    "#alternate way \n",
    "\n",
    "print('popular name is '+namesRdd.lookup(mostpopular[0])[0]+' with coappearances='+ str(mostpopular[1])) # lookup(<value>),to lookup for a value in rdd. Return list of matches if value found\n",
    "                                                                                                         #[0] after lookup() - to display value of list\n",
    "\n",
    "#print('popular name is '+namesRdd.lookup(mostpopular1[1])[0]+' with coappearances='+ str(mostpopular1[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total-Amount-By-Customer##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust = sc.textFile(\"file:///D:\\\\data\\\\customer-orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['44,8602,37.19',\n",
       " '35,5368,65.89',\n",
       " '2,3391,40.64',\n",
       " '47,6694,14.98',\n",
       " '29,680,13.08']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLine(line):\n",
    "    fields = line.split(',')\n",
    "    customerId = int(fields[0])\n",
    "    itemId = fields[1]\n",
    "    itemAmt = float(fields[2])\n",
    "    return (customerId, itemAmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(44, 4756.890000000001),\n",
       " (2, 5994.59),\n",
       " (70, 5368.249999999999),\n",
       " (14, 4735.030000000001),\n",
       " (42, 5696.840000000002)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#orders = cust.map(parseLine)\n",
    "id_amt=cust.map(lambda line: (int(line.split(',')[0]),float(line.split(',')[2])))\n",
    "totals = id_amt.reduceByKey(lambda x, y: x + y)\n",
    "totals.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4756.89 \t44.00\n",
      "5994.59 \t2.00\n",
      "5368.25 \t70.00\n",
      "4735.03 \t14.00\n",
      "5696.84 \t42.00\n"
     ]
    }
   ],
   "source": [
    "for result in totals.take(5):\n",
    "    print(\"{:.2f}\".format(result[1]),\"\\t{:.2f}\".format(result[0])) #:.2f for formatting in placeholder and then using format() to display result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min/Max -Temperatures per station ID## <same logic formax,below is only for min>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ITE00100554,18000101,TMAX,-75,,,E,',\n",
       " 'ITE00100554,18000101,TMIN,-148,,,E,',\n",
       " 'GM000010962,18000101,PRCP,0,,,E,',\n",
       " 'EZE00100082,18000101,TMAX,-86,,,E,',\n",
       " 'EZE00100082,18000101,TMIN,-135,,,E,']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"file:///D:\\\\data\\\\1800.csv\")\n",
    "lines.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To take off required fields and assigning them to variable,create function where split line on a pattern and assign variables to reqd fields.\n",
    "\n",
    "def parseLine(line):\n",
    "    fields = line.split(',')\n",
    "    stationID = fields[0]\n",
    "    entryType = fields[2]\n",
    "    temperature = float(fields[3]) * 0.1 * (9.0 / 5.0) + 32.0\n",
    "    return (stationID, entryType, temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ITE00100554', 'TMAX', 18.5),\n",
       " ('ITE00100554', 'TMIN', 5.359999999999999),\n",
       " ('GM000010962', 'PRCP', 32.0),\n",
       " ('EZE00100082', 'TMAX', 16.52),\n",
       " ('EZE00100082', 'TMIN', 7.699999999999999)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedLines=lines.map(parseLine) # use the function to actual line element of rdd\n",
    "parsedLines.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ITE00100554', 'TMIN', 5.359999999999999),\n",
       " ('EZE00100082', 'TMIN', 7.699999999999999),\n",
       " ('ITE00100554', 'TMIN', 9.5),\n",
       " ('EZE00100082', 'TMIN', 8.599999999999998),\n",
       " ('ITE00100554', 'TMIN', 23.72)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minTemps = parsedLines.filter(lambda x: \"TMIN\" in x[1]) # check if TMIN as a 1st pos value in each element of rdd,hence use filter() to filter out such elements of rdd\n",
    "minTemps.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ITE00100554', 5.359999999999999),\n",
       " ('EZE00100082', 7.699999999999999),\n",
       " ('ITE00100554', 9.5),\n",
       " ('EZE00100082', 8.599999999999998),\n",
       " ('ITE00100554', 23.72)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_temp=minTemps.map(lambda x:(x[0],x[2]))\n",
    "id_temp.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ITE00100554', 5.359999999999999), ('EZE00100082', 7.699999999999999)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minTemps = id_temp.reduceByKey(lambda x,y: x if x<y else y) # to calculate min of values (temps) per key\n",
    "minTemps.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station Id ITE00100554 has min temp of 5.36F\n",
      "station Id EZE00100082 has min temp of 7.70F\n",
      "\n",
      "station Id ITE00100554 has lowest temp of 5.36F of all stations\n"
     ]
    }
   ],
   "source": [
    "for m in minTemps.collect(): #display min temperature per station\n",
    "    print('station Id '+m[0]+' has min temp of {:.2f}F'.format(m[1]))\n",
    "    \n",
    "#to get lowest temperature and related station ID and of all stations.\n",
    "\n",
    "m=minTemps.min(lambda x:x[1]) # to get min temperature pair\n",
    "\n",
    "print('\\nstation Id '+m[0]+' has lowest temp of {:.2f}F '.format(m[1])+'of all stations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some more spark opertions on a csv file ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoData = sc.textFile(\"file:///D:\\\\data\\\\auto-data.csv\")\n",
    "autoData.cache() #action (to uncache use autoData.unpersist())\n",
    "autoData.is_cached #to check id rdd is cached #action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAKE,FUELTYPE,ASPIRE,DOORS,BODY,DRIVE,CYLINDERS,HP,RPM,MPG-CITY,MPG-HWY,PRICE',\n",
       " 'subaru,gas,std,two,hatchback,fwd,four,69,4900,31,36,5118',\n",
       " 'chevrolet,gas,std,two,hatchback,fwd,three,48,5100,47,53,5151',\n",
       " 'mazda,gas,std,two,hatchback,fwd,four,68,5000,30,31,5195',\n",
       " 'toyota,gas,std,two,hatchback,fwd,four,62,4800,35,39,5348']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoData.take(5) #action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoData.count() #action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAKE,FUELTYPE,ASPIRE,DOORS,BODY,DRIVE,CYLINDERS,HP,RPM,MPG-CITY,MPG-HWY,PRICE'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoData.first() #action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoData.saveAsTextFile('file:///D:\\\\data\\\\auto-data-saved') # this will create a folder (auto-data-saved) auto-data-saved with multiple part text files\n",
    "\n",
    "autoData.coalesce(1).saveAsTextFile('file:///D:\\\\data\\\\auto-data-saved.csv') # saveAsTextFile(<ouputfolder>)\n",
    "\n",
    "#to avoid multiple part test files being created instead 1 part text file in auto-data-saved folder,\n",
    "#use coalesce(<num of partitions>) to combine partitions together in specified num of partitions.\n",
    "# Do not repartition() as that will cause shuffle hence expensive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving rdd to file without creating folder and then file\n",
    "\n",
    "f=open(\"D:\\\\auto-data-saved.csv\",\"w\") # create new empty file in write mode\n",
    "\n",
    "f.write(\"\\n\".join(autoData.collect())) # <str1>.join(<iterable>) will join str1 with each element of iterable.In this case \\n to move each element of list to new row\n",
    "#autoDatacollect() will collect rdd to master and cerate list of elements and then join it with empty file \n",
    "\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAKE\\tFUELTYPE\\tASPIRE\\tDOORS\\tBODY\\tDRIVE\\tCYLINDERS\\tHP\\tRPM\\tMPG-CITY\\tMPG-HWY\\tPRICE',\n",
       " 'subaru\\tgas\\tstd\\ttwo\\thatchback\\tfwd\\tfour\\t69\\t4900\\t31\\t36\\t5118',\n",
       " 'chevrolet\\tgas\\tstd\\ttwo\\thatchback\\tfwd\\tthree\\t48\\t5100\\t47\\t53\\t5151',\n",
       " 'mazda\\tgas\\tstd\\ttwo\\thatchback\\tfwd\\tfour\\t68\\t5000\\t30\\t31\\t5195',\n",
       " 'toyota\\tgas\\tstd\\ttwo\\thatchback\\tfwd\\tfour\\t62\\t4800\\t35\\t39\\t5348']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvData=autoData.map(lambda x : x.replace(\",\",\"\\t\")) #replace() in map()\n",
    "tsvData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyotaData=autoData.filter(lambda x: \"toyota\" in x) # filter()\n",
    "toyotaData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toyota,gas,std,two,hatchback,fwd,four,62,4800,35,39,5348',\n",
       " 'toyota,gas,std,two,hatchback,fwd,four,62,4800,31,38,6338',\n",
       " 'toyota,gas,std,four,hatchback,fwd,four,62,4800,31,38,6488',\n",
       " 'toyota,gas,std,four,wagon,fwd,four,62,4800,31,37,6918',\n",
       " 'toyota,gas,std,four,sedan,fwd,four,70,4800,30,37,6938']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyotaData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toyota',\n",
       " 'gas',\n",
       " 'std',\n",
       " 'two',\n",
       " 'hatchback',\n",
       " 'fwd',\n",
       " 'four',\n",
       " '62',\n",
       " '4800',\n",
       " '35',\n",
       " '39',\n",
       " '5348',\n",
       " 'toyota',\n",
       " 'gas',\n",
       " 'std',\n",
       " 'two',\n",
       " 'hatchback',\n",
       " 'fwd',\n",
       " 'four',\n",
       " '62']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=toyotaData.flatMap(lambda line: line.split(\",\")) #flatMap()\n",
    "#words.count() #only one action at a time\n",
    "words.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n",
      "5\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "collData = sc.parallelize([4,3,8,5,8])\n",
    "\n",
    "for numbData in collData.distinct().take(5): # print distinct data ,keep one out of duplicates\n",
    "    print(numbData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collData.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bmw,gas,std,two,sedan,rwd,six,182,5400,16,22,41315'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoData.reduce(lambda x,y: x if len(x) < len(y) else y) # find shortest line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAKE', 'subaru', 'chevrolet', 'mazda', 'toyota']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cylData = autoData.map(lambda x: (x.split(\",\")[0], x.split(\",\")[7]))\n",
    "cylData.take(5)\n",
    "cylData.keys().take(5) # action #using take() to view result of action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('subaru', '69')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Remove header row\n",
    "\n",
    "header = cylData.first()\n",
    "cylHPData= cylData.filter(lambda line: line != header)\n",
    "cylHPData.first() # check if first line is header or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find average by Brand of vehicle##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chevrolet', ('487070', 3)),\n",
       " ('mazda', ('6868686868848484841018410110113512072', 16)),\n",
       " ('mitsubishi', ('686868881028888116116116145145145', 13)),\n",
       " ('nissan', ('696969556969696969699797152152152160160200', 18)),\n",
       " ('dodge', ('686868686810288145', 8))]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_bykey = cylHPData.combineByKey((lambda x: (x,1)),(lambda x,value:(x[0]+value,x[1]+1)),(lambda x,y:(x[0]+y[0],x[1]+y[1])))\n",
    "comb_bykey.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chevrolet', 162356.66666666666),\n",
       " ('mazda', 4.292929293030303e+35),\n",
       " ('mitsubishi', 5.283606777145293e+31),\n",
       " ('nissan', 3.872053094276094e+40),\n",
       " ('dodge', 8.585858585128602e+16)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg=comb_bykey.mapValues(lambda x:float(x[0])/float(x[1]))\n",
    "avg.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.15228426395939"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get average using reduce function and a user generated function\n",
    "\n",
    "def getMPG(autoStr) :\n",
    "    if isinstance(autoStr, int) : # check if autoStr is integer type ,using isinstance()\n",
    "        return autoStr\n",
    "    attList=autoStr.split(\",\")\n",
    "    if attList[9].isdigit() : # check if attList[9] is [0-9] ,using isdigit()\n",
    "        return int(attList[9])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#find average MPG-City for all cars\n",
    "\n",
    "autoData.reduce(lambda x,y : getMPG(x) + getMPG(y)) / (autoData.count()-1.0)  # suv=btact 1 to not account header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAKE,FUELTYPE,ASPIRE,4,BODY,DRIVE,CYLINDERS,HP,RPM,MPG-CITY,MPG-HWY,PRICE',\n",
       " 'subaru,gas,std,2,hatchback,FWD,four,69,4900,31,36,5118',\n",
       " 'chevrolet,gas,std,2,hatchback,FWD,three,48,5100,47,53,5151',\n",
       " 'mazda,gas,std,2,hatchback,FWD,four,68,5000,30,31,5195',\n",
       " 'toyota,gas,std,2,hatchback,FWD,four,62,4800,35,39,5348']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using functions for transformation\n",
    "#cleanse and transform an RDD\n",
    "\n",
    "def cleanseRDD(autoStr) :\n",
    "    if isinstance(autoStr, int) :\n",
    "        return autoStr\n",
    "    attList=autoStr.split(\",\")\n",
    "    \n",
    "    #convert doors to a number str\n",
    "    if attList[3] == \"two\" :\n",
    "         attList[3]=\"2\"\n",
    "    else :\n",
    "         attList[3]=\"4\"\n",
    "    \n",
    "    #Convert Drive to uppercase    \n",
    "    attList[5] = attList[5].upper()\n",
    "    #return attList # when this func will be caleed in map() then every line will be a list with above transformations \n",
    "    \n",
    "    # to display entire rdd as it will be before applying map() i.e when loaded from textfile with above transformations applied,\n",
    "    #then use join()\n",
    "    \n",
    "    return \",\".join(attList)\n",
    "    \n",
    "cleanedData=autoData.map(cleanseRDD)\n",
    "cleanedData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "universe\n",
      "peace\n",
      "world\n",
      "war\n",
      "\n",
      "\n",
      "peace\n",
      "war\n"
     ]
    }
   ],
   "source": [
    "#Set operations on rdd\n",
    "\n",
    "words1 = sc.parallelize([\"hello\",\"war\",\"peace\",\"world\"])\n",
    "words2 = sc.parallelize([\"war\",\"peace\",\"universe\"])\n",
    "\n",
    "for u in words1.union(words2).distinct().collect(): #remove duplicates after union()\n",
    "    print(u)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for i in words1.intersection(words2).collect(): #intersection() results in common elements\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function that splits the line as well as counts sedans and hatchbacks - using accumulator and broadcast##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Speed optimization##\n",
    "\n",
    "#Initialize accumulator\n",
    "sedanCount = sc.accumulator(0)  #sc.accumulator(<initialvalue>)\n",
    "hatchbackCount =sc.accumulator(0) \n",
    "\n",
    "#Set Broadcast variable\n",
    "\n",
    "sedanText=sc.broadcast(\"sedan\") #sc.broadcast(<broadcastvalue>)\n",
    "hatchbackText=sc.broadcast(\"hatchback\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitLines(line) :\n",
    "\n",
    "    global sedanCount # declare accumulator var as global\n",
    "    global hatchbackCount # declare accumulator var as global\n",
    "\n",
    "    # check if broadcast var.value i.e 'sedan' is in line which is passed as argument ,\n",
    "    #if found then increase accu var.value by 1 else it will remain 0\n",
    "    \n",
    "    if sedanText.value in line: # if 'sedan' in line: (if broadcast and accumulator concept not used)\n",
    "        sedanCount +=1 # to get count of 'sedan' in each line passd as argument\n",
    "        \n",
    "    if hatchbackText.value in line:\n",
    "        hatchbackCount +=1 # to get count of 'hatchback' in each line passd as argument\n",
    "        \n",
    "    return line.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 67\n"
     ]
    }
   ],
   "source": [
    "#do the map\n",
    "splitData=autoData.map(splitLines)\n",
    "\n",
    "splitData.count() # count elements of rdd\n",
    "\n",
    "print(sedanCount, hatchbackCount) # print accu and broad var set using func splitLines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total amnt per customer id and display smalledt amnt on top##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['44,8602,37.19',\n",
       " '35,5368,65.89',\n",
       " '2,3391,40.64',\n",
       " '47,6694,14.98',\n",
       " '29,680,13.08']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_ord = sc.textFile(\"file:///D:\\\\data\\\\customer-orders.csv\")\n",
    "cust_ord.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLine(line):\n",
    "    fields = line.split(\",\")\n",
    "    return (int(fields[0]), int(float(fields[2]) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(44, 3719), (35, 6589), (2, 4064), (47, 1498), (29, 1308)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = cust_ord.map(parseLine)\n",
    "c.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerOrdersSum = c.reduceByKey(lambda x, y: x + y) # get total amnt per cust id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(330937, 45), (379053, 79), (392417, 96), (404260, 23), (417222, 99)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customerOrdersSorted = customerOrdersSum.map(lambda x: (x[1], x[0])).sortByKey() #sort amnt\n",
    "customerOrdersSorted.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer id: 45with amnt: 3309.37\n",
      "customer id: 79with amnt: 3790.53\n",
      "customer id: 96with amnt: 3924.17\n",
      "customer id: 23with amnt: 4042.6\n",
      "customer id: 99with amnt: 4172.22\n"
     ]
    }
   ],
   "source": [
    "for i in customerOrdersSorted.take(5):\n",
    "    print('customer id: '+ str(i[1])+'with amnt: '+str(i[0]/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD can be created from list containing dict,or list or tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Simple DataFrame from a Tuple List##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [('a', 1), ('b', 2), ('c', 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| _1| _2|\n",
      "+---+---+\n",
      "|  a|  1|\n",
      "|  b|  2|\n",
      "|  c|  3|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(a_list) # schema not given\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|let|num|\n",
      "+---+---+\n",
      "|  a|  1|\n",
      "|  b|  2|\n",
      "|  c|  3|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=spark.createDataFrame(a_list,['let','num']) # schema given (infer schema)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- let: string (nullable = true)\n",
      " |-- num: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Simple DataFrame from a Dictionary##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dict = [{'letters': 'a', 'numbers': 1},\n",
    "          {'letters': 'b', 'numbers': 2},\n",
    "          {'letters': 'c', 'numbers': 3}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\spark-2.3.2-bin-hadoop2.7\\python\\pyspark\\sql\\session.py:340: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=spark.createDataFrame(a_dict) # no schema given infer schema) .Warning but still dataframe will be created\n",
    "df2.show() # by default 20 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Simple DataFrame Using a StructType Schema + RDD##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=StructType([StructField('letters', StringType(), True),StructField('numbers', IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1=sc.parallelize(a_list)\n",
    "df1=spark.createDataFrame(rdd1,schema) # schema programatically gieven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Inspection Functions:##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['letters', 'numbers']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('letters', 'string'), ('numbers', 'int')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(letters,StringType,true),StructField(numbers,IntegerType,true)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(letters='a', numbers=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(letters='a', numbers=1),\n",
       " Row(letters='b', numbers=2),\n",
       " Row(letters='c', numbers=3)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5) #default 1 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(letters='a', numbers=1),\n",
       " Row(letters='b', numbers=2),\n",
       " Row(letters='c', numbers=3)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "|summary|letters|numbers|\n",
      "+-------+-------+-------+\n",
      "|  count|      3|      3|\n",
      "|   mean|   null|    2.0|\n",
      "| stddev|   null|    1.0|\n",
      "|    min|      a|      1|\n",
      "|    max|      c|      3|\n",
      "+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Scan ExistingRDD[letters#36,numbers#37]\n"
     ]
    }
   ],
   "source": [
    "df1.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[letters: string, numbers: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df1) # displays type of object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      c|      3|\n",
      "|      b|      2|\n",
      "|      a|      1|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1['letters','numbers'].orderBy(col('letters').desc()).show() # A way to sort column in dataframe without using select()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use these functions:##\n",
    "\n",
    "##unionAll()/union(): combine two DataFrames together ##\n",
    "##orderBy()/sort(): perform sorting of DataFrame columns ##\n",
    "##select(): select which DataFrame columns to retain ##\n",
    "##drop(): select a single DataFrame column to remove ##\n",
    "##filter(): retain DataFrame rows that match a condition ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.unionAll(df1).show() # unionAll() produce duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df1.select('letters','numbers').show()\n",
    "#df1.select(col('letters'),col('numbers')).show()\n",
    "#df1.select(df1['letters'],df1['numbers']).show()\n",
    "df1.select(['letters','numbers']).show()  # selecting muliple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df1).show() # union() also produce duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      b|      2|\n",
      "|      a|      1|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df1).distinct().show() # remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      b|      2|\n",
      "|      a|      1|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df1).dropDuplicates().show() # remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.orderBy('numbers').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      c|      3|\n",
      "|      b|      2|\n",
      "|      a|      1|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.orderBy(col('numbers').desc()).show() # using col() & desc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      c|      3|\n",
      "|      b|      2|\n",
      "|      a|      1|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.orderBy('numbers',ascending=False).show()# imp to write 'ascending=' instead of just False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n",
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      c|      3|\n",
      "|      b|      2|\n",
      "|      a|      1|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.sort(col('numbers')).show() # using sort()\n",
    "\n",
    "df1.sort(col('numbers').desc()).show() # descending using sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|numbers|\n",
      "+-------+\n",
      "|      1|\n",
      "|      2|\n",
      "|      3|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.drop('letters').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here is some numeric filtering with comparison operators\n",
    "# (>, <, >=, <=, ==, != all work)\n",
    "\n",
    "df1.filter(df1.numbers>1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      b|      2|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter((df1.numbers>1) & (df1.numbers<3)).show() # multiple conditions in individual brackets\n",
    "\n",
    "# use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(col('letters').isin(['a', 'b'])).show() # alternate way of filtering data using isin() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(col('letters').isin(['a', 'b'])==False).show() # to implement is not in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using groupBy(): ##\n",
    "    \n",
    "#count(): counts the number of records for each group#\n",
    "#sum(): compute the sum for each numeric column for each group#\n",
    "#min(): computes the minimum value for each numeric column for each group#\n",
    "#max(): computes the maximum value for each numeric column for each group#\n",
    "#avg() or mean(): computes average values for each numeric columns for each group#\n",
    "#pivot(): pivots a column of the current DataFrame and perform the specified aggregation#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycflights_schema = StructType([\n",
    "  StructField('year', IntegerType(), True),\n",
    "  StructField('month', IntegerType(), True),\n",
    "  StructField('day', IntegerType(), True),\n",
    "  StructField('dep_time', StringType(), True),\n",
    "  StructField('dep_delay', IntegerType(), True),\n",
    "  StructField('arr_time', StringType(), True),\n",
    "  StructField('arr_delay', IntegerType(), True),\n",
    "  StructField('carrier', StringType(), True),\n",
    "  StructField('tailnum', StringType(), True),\n",
    "  StructField('flight', StringType(), True),  \n",
    "  StructField('origin', StringType(), True),\n",
    "  StructField('dest', StringType(), True),\n",
    "  StructField('air_time', IntegerType(), True),\n",
    "  StructField('distance', IntegerType(), True),\n",
    "  StructField('hour', IntegerType(), True),\n",
    "  StructField('minute', IntegerType(), True)\n",
    "  ])\n",
    "\n",
    "nycflights = \\\n",
    "(spark\n",
    " .read\n",
    " .format('csv')\n",
    " .options(header = True,inferSchema=True) # if inferSchema-=True is not specified then spark will read all column as string type column\n",
    " .load('file:///D:\\\\data\\\\nycflights13.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "|2013|    1|  1|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|     227|    1400|   5|    17|\n",
      "|2013|    1|  1|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|     227|    1416|   5|    33|\n",
      "|2013|    1|  1|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|     160|    1089|   5|    42|\n",
      "|2013|    1|  1|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|     183|    1576|   5|    44|\n",
      "|2013|    1|  1|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|     116|     762|   5|    54|\n",
      "|2013|    1|  1|     554|       -4|     740|       12|     UA| N39463|  1696|   EWR| ORD|     150|     719|   5|    54|\n",
      "|2013|    1|  1|     555|       -5|     913|       19|     B6| N516JB|   507|   EWR| FLL|     158|    1065|   5|    55|\n",
      "|2013|    1|  1|     557|       -3|     709|      -14|     EV| N829AS|  5708|   LGA| IAD|      53|     229|   5|    57|\n",
      "|2013|    1|  1|     557|       -3|     838|       -8|     B6| N593JB|    79|   JFK| MCO|     140|     944|   5|    57|\n",
      "|2013|    1|  1|     558|       -2|     753|        8|     AA| N3ALAA|   301|   LGA| ORD|     138|     733|   5|    58|\n",
      "|2013|    1|  1|     558|       -2|     849|       -2|     B6| N793JB|    49|   JFK| PBI|     149|    1028|   5|    58|\n",
      "|2013|    1|  1|     558|       -2|     853|       -3|     B6| N657JB|    71|   JFK| TPA|     158|    1005|   5|    58|\n",
      "|2013|    1|  1|     558|       -2|     924|        7|     UA| N29129|   194|   JFK| LAX|     345|    2475|   5|    58|\n",
      "|2013|    1|  1|     558|       -2|     923|      -14|     UA| N53441|  1124|   EWR| SFO|     361|    2565|   5|    58|\n",
      "|2013|    1|  1|     559|       -1|     941|       31|     AA| N3DUAA|   707|   LGA| DFW|     257|    1389|   5|    59|\n",
      "|2013|    1|  1|     559|        0|     702|       -4|     B6| N708JB|  1806|   JFK| BOS|      44|     187|   5|    59|\n",
      "|2013|    1|  1|     559|       -1|     854|       -8|     UA| N76515|  1187|   EWR| LAS|     337|    2227|   5|    59|\n",
      "|2013|    1|  1|     600|        0|     851|       -7|     B6| N595JB|   371|   LGA| FLL|     152|    1076|   6|     0|\n",
      "|2013|    1|  1|     600|        0|     837|       12|     MQ| N542MQ|  4650|   LGA| ATL|     134|     762|   6|     0|\n",
      "|2013|    1|  1|     601|        1|     844|       -6|     B6| N644JB|   343|   EWR| PBI|     147|    1023|   6|     1|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycflights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- dep_time: integer (nullable = true)\n",
      " |-- dep_delay: integer (nullable = true)\n",
      " |-- arr_time: integer (nullable = true)\n",
      " |-- arr_delay: integer (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- air_time: integer (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- minute: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycflights.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[year: int, month: int, day: int, dep_time: int, dep_delay: int, arr_time: int, arr_delay: int, carrier: string, tailnum: string, flight: int, origin: string, dest: string, air_time: int, distance: int, hour: int, minute: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(nycflights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|month|count|\n",
      "+-----+-----+\n",
      "|   12|28135|\n",
      "|    1|27004|\n",
      "|    6|28243|\n",
      "|    3|28834|\n",
      "|    5|28796|\n",
      "|    9|27574|\n",
      "|    4|28330|\n",
      "|    8|29327|\n",
      "|    7|29425|\n",
      "|   10|28889|\n",
      "|   11|27268|\n",
      "|    2|24951|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycflights.groupby('month').count().show() # creates a new column with aggregate `count` values and groupBy Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+------------------+\n",
      "|month|max(arr_delay)|    avg(dep_delay)|\n",
      "+-----+--------------+------------------+\n",
      "|   12|           878|16.576687569162672|\n",
      "|    1|          1272|10.036665030396858|\n",
      "|    6|          1127|20.846331791143424|\n",
      "|    3|           915|13.227076109105209|\n",
      "|    5|           875|12.986859348988771|\n",
      "|    9|          1007|6.7224762185679525|\n",
      "|    4|           931|13.938037741305763|\n",
      "|    8|           490|12.611039839117922|\n",
      "|    7|           989|21.727786554326837|\n",
      "|   10|           688| 6.243988413080655|\n",
      "|   11|           796|  5.43536156833734|\n",
      "|    2|           834|10.816842549598986|\n",
      "+-----+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycflights.groupby('month').agg({'dep_delay': 'avg', 'arr_delay': 'max'}).show() # multiple aggreagtion func on diff columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+-----+\n",
      "|month|origin|dest|count|\n",
      "+-----+------+----+-----+\n",
      "|    1|   JFK| LAX|  937|\n",
      "|    1|   LGA| ATL|  878|\n",
      "|    1|   JFK| SFO|  671|\n",
      "|    1|   LGA| ORD|  583|\n",
      "|    1|   EWR| ORD|  502|\n",
      "|    1|   JFK| BOS|  486|\n",
      "|    1|   JFK| MCO|  456|\n",
      "|    1|   LGA| MIA|  451|\n",
      "|    1|   JFK| FLL|  439|\n",
      "|    1|   LGA| CLT|  437|\n",
      "+-----+------+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycflights.groupby('month', 'origin', 'dest').count().orderBy('month', 'count',ascending = [1, 0]).show(10)\n",
    "\n",
    "#nycflights.groupby(['month', 'origin', 'dest']).count().orderBy(['month', 'count'],ascending = [1, 0]).show(10)\n",
    "\n",
    "# group by on multiple columns                          \n",
    "# perform a 'count' aggregation on the groups\n",
    "#orderBY on multiple col with diff sorting order for each col\n",
    "#ascending=[1,0] means ascending is true for 'month' col and false(i.e descending) for 'count' col.\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[month: int, count: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "  nycflights\n",
    "  .groupBy('month')\n",
    "  .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|carrier|               EWR|               JFK|               LGA|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|     UA| 12.52286865854727|               7.9|12.087916294500447|\n",
      "|     AA|10.035419126328216|10.302155109221522| 6.705769103100312|\n",
      "|     EV| 20.16493117893477|18.520361990950228| 19.12549969715324|\n",
      "|     B6|13.100262224278882|12.757453126122458|14.805738396624472|\n",
      "|     DL|12.084592145015106| 8.333187709334497|  9.57299733123332|\n",
      "|     OO|20.833333333333332|              null|10.434782608695652|\n",
      "|     F9|              null|              null|20.215542521994134|\n",
      "|     YV|              null|              null|18.996330275229358|\n",
      "|     US| 3.735103926096998| 5.866958571909734|3.3065054875139177|\n",
      "|     MQ|17.467267552182165|13.199970870958346| 8.528568781271234|\n",
      "|     HA|              null| 4.900584795321637|              null|\n",
      "|     AS| 5.804775280898877|              null|              null|\n",
      "|     FL|              null|              null| 18.72607467838092|\n",
      "|     VX|11.927377892030849|13.279440559440559|              null|\n",
      "|     WN|17.864376130198917|              null|            17.557|\n",
      "|     9E| 5.951666666666667|19.001516902629298| 8.894182124789207|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=nycflights.groupBy('carrier').pivot('origin').avg('dep_delay') # groupBy() with pivot() and aggregation.\n",
    "\n",
    "x.show()\n",
    "\n",
    "# pivot(col name)- will produce pivot col as oe col grouped values as one column and pivot unique column values \n",
    "# null will be the value fof pivot col if aggregation can't be done\n",
    "#as different columns having calculate aggregation accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Operations ##\n",
    "\n",
    "#format_number(<num>,<d>): apply formatting to a number, rounded to d decimal places, and return the result as a string\n",
    "#when() & otherwise(): when() evaluates a list of conditions and returns one of multiple possible result expressions; if     \n",
    "    \n",
    "                       #otherwise() is not invoked, None is returned for unmatched conditions\n",
    "#concat_ws(): concatenates multiple input string columns together into a single string column, using the given separator\n",
    "#to_utc_timestamp(): assumes the given timestamp is in given timezone and converts to UTC\n",
    "#year(): extracts the year of a given date as integer\n",
    "#month(): extracts the month of a given date as integer\n",
    "#dayofmonth(): extracts the day of the month of a given date as integer\n",
    "#hour(): extract the hour of a given date as integer\n",
    "#minute(): extract the minute of a given date as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+--------------+\n",
      "|month|mean_arr_delay|mean_dep_delay|\n",
      "+-----+--------------+--------------+\n",
      "|   12|          14.9|          16.6|\n",
      "|    1|           6.1|          10.0|\n",
      "|    6|          16.5|          20.8|\n",
      "|    3|           5.8|          13.2|\n",
      "|    5|           3.5|          13.0|\n",
      "|    9|          -4.0|           6.7|\n",
      "|    4|          11.2|          13.9|\n",
      "|    8|           6.0|          12.6|\n",
      "|    7|          16.7|          21.7|\n",
      "|   10|          -0.2|           6.2|\n",
      "|   11|           0.5|           5.4|\n",
      "|    2|           5.6|          10.8|\n",
      "+-----+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycflights \\\n",
    "  .groupby('month') \\\n",
    "  .agg({'dep_delay': 'avg', 'arr_delay': 'avg'})\\\n",
    "  .withColumnRenamed('avg(arr_delay)', 'mean_arr_delay') \\\n",
    "  .withColumnRenamed('avg(dep_delay)', 'mean_dep_delay')\\\n",
    "  .withColumn('mean_arr_delay', format_number('mean_arr_delay', 1))\\\n",
    "  .withColumn('mean_dep_delay', format_number('mean_dep_delay', 1)).show()\n",
    "\n",
    "# withColumnRenamed(): oldcol name and new col name as arguments\n",
    "# withColumn() : new/old col name  and col expression as arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+-----------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|far_or_near|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+-----------+\n",
      "|2013|    1|  1|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|     227|    1400|   5|    17|        far|\n",
      "|2013|    1|  1|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|     227|    1416|   5|    33|        far|\n",
      "|2013|    1|  1|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|     160|    1089|   5|    42|        far|\n",
      "|2013|    1|  1|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|     183|    1576|   5|    44|        far|\n",
      "|2013|    1|  1|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|     116|     762|   5|    54|       near|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycflights.withColumn('far_or_near',when(nycflights.distance>1000,'far').otherwise('near')).show(5) # using when () and otherwise()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+---------------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|dist_per_minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+---------------+\n",
      "|2013|    1|  1|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|     227|    1400|   5|    17|           6.17|\n",
      "|2013|    1|  1|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|     227|    1416|   5|    33|           6.24|\n",
      "|2013|    1|  1|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|     160|    1089|   5|    42|           6.81|\n",
      "|2013|    1|  1|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|     183|    1576|   5|    44|           8.61|\n",
      "|2013|    1|  1|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|     116|     762|   5|    54|           6.57|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycflights.withColumn('dist_per_minute',nycflights.distance / nycflights.air_time)\\\n",
    "           .withColumn('dist_per_minute',format_number('dist_per_minute', 2)).show(5)\n",
    "\n",
    "#multiple transformation for one column in withColumn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+----+------+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|hour|minute|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+----+------+\n",
      "|2013|    1|  1|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|   5|    17|\n",
      "|2013|    1|  1|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|   5|    33|\n",
      "|2013|    1|  1|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|   5|    42|\n",
      "|2013|    1|  1|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|   5|    44|\n",
      "|2013|    1|  1|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|   5|    54|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycflights.drop('distance').drop('air_time').show(5) # drop() to drop col names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a proper date and time to form final timestamp.\n",
    "\n",
    "# Use `concat_ws()` (concatentate with separator) to\n",
    "# combine column data into StringType columns such\n",
    "# that dates (`-` separator, YYYY-MM-DD) and times\n",
    "# (`:` separator, 24-hour time) are formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+--------+----+\n",
      "|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|    date|time|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+--------+----+\n",
      "|2013|    1|  1|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|     227|    1400|   5|    17|2013-1-1|5:17|\n",
      "|2013|    1|  1|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|     227|    1416|   5|    33|2013-1-1|5:33|\n",
      "|2013|    1|  1|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|     160|    1089|   5|    42|2013-1-1|5:42|\n",
      "|2013|    1|  1|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|     183|    1576|   5|    44|2013-1-1|5:44|\n",
      "|2013|    1|  1|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|     116|     762|   5|    54|2013-1-1|5:54|\n",
      "+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1.create separate data and time column\n",
    "\n",
    "nycflights=nycflights\\\n",
    " .withColumn('date',concat_ws('-',nycflights.year,\\\n",
    "                       nycflights.month,\\\n",
    "                       nycflights.day))\\\n",
    " .withColumn('time',\\\n",
    "             concat_ws(':',\\\n",
    "                       nycflights.hour,\\\n",
    "                       nycflights.minute))\n",
    "# concat_ws to add separator '-' to form correct date\n",
    "\n",
    "nycflights.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year', 'int'),\n",
       " ('month', 'int'),\n",
       " ('day', 'int'),\n",
       " ('dep_time', 'int'),\n",
       " ('dep_delay', 'int'),\n",
       " ('arr_time', 'int'),\n",
       " ('arr_delay', 'int'),\n",
       " ('carrier', 'string'),\n",
       " ('tailnum', 'string'),\n",
       " ('flight', 'int'),\n",
       " ('origin', 'string'),\n",
       " ('dest', 'string'),\n",
       " ('air_time', 'int'),\n",
       " ('distance', 'int'),\n",
       " ('hour', 'int'),\n",
       " ('minute', 'int'),\n",
       " ('date', 'string'),\n",
       " ('time', 'string')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nycflights.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+--------------+\n",
      "|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|timestamp_temp|\n",
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+--------------+\n",
      "|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|     227|    1400| 2013-1-1 5:17|\n",
      "|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|     227|    1416| 2013-1-1 5:33|\n",
      "|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|     160|    1089| 2013-1-1 5:42|\n",
      "|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|     183|    1576| 2013-1-1 5:44|\n",
      "|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|     116|     762| 2013-1-1 5:54|\n",
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.concatenate data and time column\n",
    "\n",
    "a=nycflights.withColumn('timestamp_temp',concat_ws(' ',nycflights.date,nycflights.time)).drop('year','month','day','hour','minute','date','time')\n",
    "\n",
    "# dropping multiple columns in drop ()\n",
    "\n",
    "a.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+\n",
      "|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|          timestamp|\n",
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+\n",
      "|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|     227|    1400|2013-01-01 05:17:00|\n",
      "|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|     227|    1416|2013-01-01 05:33:00|\n",
      "|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|     160|    1089|2013-01-01 05:42:00|\n",
      "|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|     183|    1576|2013-01-01 05:44:00|\n",
      "|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|     116|     762|2013-01-01 05:54:00|\n",
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.convert the `timestamp` from a StringType into a TimestampType using to_utc_timestamp()\n",
    "# to_utc_timestamp(<timestamp>,<'<timezone>'>)\n",
    "\n",
    "b=a.withColumn('timestamp',to_utc_timestamp(a.timestamp_temp,'GMT')).drop('timestamp_temp')\n",
    "b.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dep_time',\n",
       " 'dep_delay',\n",
       " 'arr_time',\n",
       " 'arr_delay',\n",
       " 'carrier',\n",
       " 'tailnum',\n",
       " 'flight',\n",
       " 'origin',\n",
       " 'dest',\n",
       " 'air_time',\n",
       " 'distance',\n",
       " 'timestamp']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make timestamp column be the first column\n",
    "#Recall -'columns' contain list of columns.Apply slicing to achieve result.\n",
    "\n",
    "b.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=[1,2,3,4,5]\n",
    "\n",
    "#x[0],x[-1]=x[-1],x[0] # reverse a list\n",
    "\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'timestamp'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.columns[-1] # gives column name in string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timestamp']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.columns[-1:] # by applying slicing ,it gives same column name in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dep_time',\n",
       " 'dep_delay',\n",
       " 'arr_time',\n",
       " 'arr_delay',\n",
       " 'carrier',\n",
       " 'tailnum',\n",
       " 'flight',\n",
       " 'origin',\n",
       " 'dest',\n",
       " 'air_time',\n",
       " 'distance']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.columns[0:-1] # give col names from 0 pos till end-1 in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+\n",
      "|          timestamp|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|\n",
      "+-------------------+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+\n",
      "|2013-01-01 05:17:00|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|     227|    1400|\n",
      "|2013-01-01 05:33:00|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|     227|    1416|\n",
      "|2013-01-01 05:42:00|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|     160|    1089|\n",
      "|2013-01-01 05:44:00|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|     183|    1576|\n",
      "|2013-01-01 05:54:00|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|     116|     762|\n",
      "+-------------------+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# changing position of timestamp from last to first\n",
    "\n",
    "b.select(b.columns[-1:] + b.columns[0:-1]).show(5) # adding two lists from above\n",
    "\n",
    "# here, if b.columns[-1] is written then concatenation will not work as this will be string column name and 2nd (b.columns[0:-1])\n",
    "# will result in list of columns.concatenation cannot occur between string a list.Thus use slicing and add the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+----+-----+---+----+------+\n",
      "|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|          timestamp|year|month|day|hour|minute|\n",
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+----+-----+---+----+------+\n",
      "|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|     227|    1400|2013-01-01 05:17:00|2013|    1|  1|   5|    17|\n",
      "|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|     227|    1416|2013-01-01 05:33:00|2013|    1|  1|   5|    33|\n",
      "|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|     160|    1089|2013-01-01 05:42:00|2013|    1|  1|   5|    42|\n",
      "|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|     183|    1576|2013-01-01 05:44:00|2013|    1|  1|   5|    44|\n",
      "|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|     116|     762|2013-01-01 05:54:00|2013|    1|  1|   5|    54|\n",
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+----+-----+---+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using date and time functions to create columns.\n",
    "\n",
    "b\\\n",
    ".withColumn('year', year(b.timestamp))\\\n",
    ".withColumn('month', month(b.timestamp))\\\n",
    ".withColumn('day', dayofmonth(b.timestamp))\\\n",
    ".withColumn('hour', hour(b.timestamp))\\\n",
    ".withColumn('minute', minute(b.timestamp)).show(5)\n",
    "\n",
    "#year(<date/timestamp>)\n",
    "#month(<date/timestamp>)\n",
    "#dayofmonth(<date/timestamp>)\n",
    "#hour(<time/timestamp>)\n",
    "#minute(<time/timestamp>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+\n",
      "|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|          timestamp|\n",
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+\n",
      "|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|     227|    1400|2013-01-01 05:17:00|\n",
      "|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|     227|    1416|2013-01-01 05:33:00|\n",
      "|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|     160|    1089|2013-01-01 05:42:00|\n",
      "|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|     183|    1576|2013-01-01 05:44:00|\n",
      "|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|     116|     762|2013-01-01 05:54:00|\n",
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b.limit(5).show() # limit(n)- first n records\n",
    "                  #same as head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Date functions:##\n",
    "\n",
    "#date_sub(): subtract an integer number of days from a Date or Timestamp\n",
    "#date_add(): add an integer number of days from a Date or Timestamp\n",
    "#datediff(): get the difference between two dates\n",
    "#add_months(): add an integer number of months\n",
    "#months_between(): get the number of months between two dates\n",
    "#next_day(<date>,<day(in 2 letter,3 letter or full text form)>): returns the first date (as per day of current/later week             \n",
    "                                                                #specified)which is later than the value of the date column\n",
    "#last_day(): returns the last day of the month which the given date belongs to\n",
    "#dayofmonth(): extract the day of the month of a given date as integer\n",
    "#dayofyear(): extract the day of the year of a given date as integer\n",
    "#weekofyear(): extract the week number of a given date as integer\n",
    "#quarter(): extract the quarter of a given date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------+\n",
      "|          timestamp|next_day(timestamp, Wed)|\n",
      "+-------------------+------------------------+\n",
      "|2013-01-01 05:17:00|              2013-01-02|\n",
      "|2013-01-01 05:33:00|              2013-01-02|\n",
      "|2013-01-01 05:42:00|              2013-01-02|\n",
      "|2013-01-01 05:44:00|              2013-01-02|\n",
      "|2013-01-01 05:54:00|              2013-01-02|\n",
      "+-------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b.select(col('timestamp'),next_day('timestamp','Wed')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------+\n",
      "|          timestamp|next_day(timestamp, Mon)|\n",
      "+-------------------+------------------------+\n",
      "|2013-01-01 05:17:00|              2013-01-07|\n",
      "|2013-01-01 05:33:00|              2013-01-07|\n",
      "|2013-01-01 05:42:00|              2013-01-07|\n",
      "|2013-01-01 05:44:00|              2013-01-07|\n",
      "|2013-01-01 05:54:00|              2013-01-07|\n",
      "+-------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b.select(col('timestamp'),next_day('timestamp','Mon')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+--------+----------+--------------+----------+----------+----------+---------+----------+-------+---+----------+----------------------+\n",
      "|timestamp          |date_sub  |date_add  |datediff|add_months|months_between|next_day  |last_day  |dayofmonth|dayofyear|weekofyear|quarter|sec|to_date   |curr_timestamp        |\n",
      "+-------------------+----------+----------+--------+----------+--------------+----------+----------+----------+---------+----------+-------+---+----------+----------------------+\n",
      "|2013-01-01 05:17:00|2012-12-25|2013-01-08|0       |2013-02-01|0.0           |2013-01-07|2013-01-31|1         |1        |1         |1      |0  |2013-01-01|2019-01-06 14:09:04.39|\n",
      "|2013-01-01 05:33:00|2012-12-25|2013-01-08|0       |2013-02-01|0.0           |2013-01-07|2013-01-31|1         |1        |1         |1      |0  |2013-01-01|2019-01-06 14:09:04.39|\n",
      "|2013-01-01 05:42:00|2012-12-25|2013-01-08|0       |2013-02-01|0.0           |2013-01-07|2013-01-31|1         |1        |1         |1      |0  |2013-01-01|2019-01-06 14:09:04.39|\n",
      "|2013-01-01 05:44:00|2012-12-25|2013-01-08|0       |2013-02-01|0.0           |2013-01-07|2013-01-31|1         |1        |1         |1      |0  |2013-01-01|2019-01-06 14:09:04.39|\n",
      "|2013-01-01 05:54:00|2012-12-25|2013-01-08|0       |2013-02-01|0.0           |2013-01-07|2013-01-31|1         |1        |1         |1      |0  |2013-01-01|2019-01-06 14:09:04.39|\n",
      "+-------------------+----------+----------+--------+----------+--------------+----------+----------+----------+---------+----------+-------+---+----------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=b\\\n",
    "   .select('timestamp')\\\n",
    "   .withColumn('date_sub', date_sub(b.timestamp, 7))\\\n",
    "   .withColumn('date_add', date_add(b.timestamp, 7))\\\n",
    "   .withColumn('datediff', datediff(b.timestamp, b.timestamp))\\\n",
    "   .withColumn('add_months', add_months(b.timestamp, 1))\\\n",
    "   .withColumn('months_between', months_between(b.timestamp, b.timestamp))\\\n",
    "   .withColumn('next_day', next_day(b.timestamp, 'Mon'))\\\n",
    "   .withColumn('last_day', last_day(b.timestamp))\\\n",
    "   .withColumn('dayofmonth', dayofmonth(b.timestamp))\\\n",
    "   .withColumn('dayofyear', dayofyear(b.timestamp))\\\n",
    "   .withColumn('weekofyear', weekofyear(b.timestamp))\\\n",
    "   .withColumn('quarter', quarter(b.timestamp))\\\n",
    "   .withColumn('sec',second(b.timestamp))\\\n",
    "   .withColumn('to_date',to_date(b.timestamp))\\\n",
    "   .withColumn('curr_timestamp',current_timestamp()) # no argument for current_date()/current_timestamp()\n",
    "\n",
    "x.show(5,False)\n",
    "\n",
    "\n",
    "#to_timestmap() works same as to_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins ##\n",
    "#Joins are easily performed with Spark DataFrames. The expression:\n",
    "\n",
    "#join(other, on = None, how = None)\n",
    "\n",
    "#where:\n",
    "\n",
    "#other: a DataFrame that serves as the right side of the join\n",
    "#on: typically a join expression\n",
    "#how: the default is inner but there are also inner, outer, left_outer, right_outer, and leftsemi joins available\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's load in some more data so that we can have two DataFrames to join. The CSV file weather.csv contains \n",
    "#hourly meteorological data from EWR during 2013.\n",
    "\n",
    "#Create a schema\n",
    "\n",
    "weather_schema = StructType([  \n",
    "  StructField('year', IntegerType(), True),\n",
    "  StructField('month', IntegerType(), True),\n",
    "  StructField('day', IntegerType(), True),\n",
    "  StructField('hour', IntegerType(), True),\n",
    "  StructField('temp', FloatType(), True),\n",
    "  StructField('dewp', FloatType(), True),\n",
    "  StructField('humid', FloatType(), True),\n",
    "  StructField('wind_dir', IntegerType(), True),\n",
    "  StructField('wind_speed', FloatType(), True),\n",
    "  StructField('wind_gust', FloatType(), True),\n",
    "  StructField('precip', FloatType(), True),\n",
    "  StructField('pressure', FloatType(), True),\n",
    "  StructField('visib', FloatType(), True)\n",
    "  ])\n",
    "\n",
    "#read the CSV with schema specified (not inferred) using .schema\n",
    "\n",
    "weather = \\\n",
    "spark\\\n",
    " .read\\\n",
    " .format('csv')\\\n",
    " .schema(weather_schema)\\\n",
    " .options(header = True)\\\n",
    " .csv('file:///D:\\\\data\\\\weather.csv') # or .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+-----+-----+-----+--------+----------+---------+------+--------+-----+\n",
      "|year|month|day|hour| temp| dewp|humid|wind_dir|wind_speed|wind_gust|precip|pressure|visib|\n",
      "+----+-----+---+----+-----+-----+-----+--------+----------+---------+------+--------+-----+\n",
      "|2013|    1|  1|   0|37.04|21.92|53.97|     230|  10.35702|11.918652|   0.0|  1013.9| 10.0|\n",
      "|2013|    1|  1|   1|37.04|21.92|53.97|     230|  13.80936|15.891536|   0.0|  1013.0| 10.0|\n",
      "|2013|    1|  1|   2|37.94|21.92|52.09|     230|  12.65858|14.567241|   0.0|  1012.6| 10.0|\n",
      "|2013|    1|  1|   3|37.94| 23.0|54.51|     230|  13.80936|15.891536|   0.0|  1012.7| 10.0|\n",
      "|2013|    1|  1|   4|37.94|24.08|57.04|     240|  14.96014| 17.21583|   0.0|  1012.8| 10.0|\n",
      "+----+-----+---+----+-----+-----+-----+--------+----------+---------+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+-----+---+----+\n",
      "|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|          timestamp|month|day|hour|\n",
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+-----+---+----+\n",
      "|     517|        2|     830|       11|     UA| N14228|  1545|   EWR| IAH|     227|    1400|2013-01-01 05:17:00|    1|  1|   5|\n",
      "|     533|        4|     850|       20|     UA| N24211|  1714|   LGA| IAH|     227|    1416|2013-01-01 05:33:00|    1|  1|   5|\n",
      "|     542|        2|     923|       33|     AA| N619AA|  1141|   JFK| MIA|     160|    1089|2013-01-01 05:42:00|    1|  1|   5|\n",
      "|     544|       -1|    1004|      -18|     B6| N804JB|   725|   JFK| BQN|     183|    1576|2013-01-01 05:44:00|    1|  1|   5|\n",
      "|     554|       -6|     812|      -25|     DL| N668DN|   461|   LGA| ATL|     116|     762|2013-01-01 05:54:00|    1|  1|   5|\n",
      "+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+-------------------+-----+---+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df=b.withColumn('month', month(b.timestamp))\\\n",
    " .withColumn('day', dayofmonth(b.timestamp))\\\n",
    " .withColumn('hour', hour(b.timestamp))\n",
    "\n",
    "flights_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+------+------+----+--------+----------+---------+-----+\n",
      "|          timestamp|carrier|flight|origin|dest|wind_dir|wind_speed|wind_gust|visib|\n",
      "+-------------------+-------+------+------+----+--------+----------+---------+-----+\n",
      "|2013-01-01 05:17:00|     UA|  1545|   EWR| IAH|    null|      null|     null| null|\n",
      "|2013-01-01 05:33:00|     UA|  1714|   LGA| IAH|    null|      null|     null| null|\n",
      "|2013-01-01 05:42:00|     AA|  1141|   JFK| MIA|    null|      null|     null| null|\n",
      "|2013-01-01 05:44:00|     B6|   725|   JFK| BQN|    null|      null|     null| null|\n",
      "|2013-01-01 05:54:00|     DL|   461|   LGA| ATL|    null|      null|     null| null|\n",
      "+-------------------+-------+------+------+----+--------+----------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#join flights df with weather df\n",
    "\n",
    "\n",
    "flights_weath=flights_df.join(weather,\\\n",
    "        [flights_df.month == weather.month,\\\n",
    "        flights_df.day == weather.day,\\\n",
    "        flights_df.hour == weather.hour],\\\n",
    "       'left_outer').select('timestamp', 'carrier', 'flight','origin', 'dest','wind_dir','wind_speed','wind_gust', 'visib')\n",
    "\n",
    "# selecting columns from joined df\n",
    "\n",
    "flights_weath.show(5)\n",
    "\n",
    "# join() - mutiple key condition should be given in a list and key condition should have == instead of =\n",
    "# left outer join: keep all rows from the left DF (flights), with the matching rows in the right DF (weather)\n",
    "                      # NULLs created if there is no match to the right DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------+---------------+\n",
      "|force|speed_mi_h_lb|speed_mi_h_ub|           name|\n",
      "+-----+-------------+-------------+---------------+\n",
      "|    0|            0|            1|           calm|\n",
      "|    1|            1|            4|      light air|\n",
      "|    2|            5|            7|   light breeze|\n",
      "|    3|            8|           11|  gentle breeze|\n",
      "|    4|           12|           18|moderate breeze|\n",
      "+-----+-------------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load beaufort_land csv\n",
    "\n",
    "#create schema\n",
    "\n",
    "beaufort_land_schema = StructType([  \n",
    "  StructField('force', IntegerType(), True),\n",
    "  StructField('speed_mi_h_lb', IntegerType(), True),\n",
    "  StructField('speed_mi_h_ub', IntegerType(), True),\n",
    "  StructField('name', StringType(), True)\n",
    "  ])\n",
    "\n",
    "# read the CSV with the schema\n",
    "bl = \\\n",
    "spark\\\n",
    " .read\\\n",
    " .format('csv')\\\n",
    " .schema(beaufort_land_schema)\\\n",
    " .options(header = True)\\\n",
    " .load('file:///D:\\\\data\\\\beaufort_land.csv')\n",
    "\n",
    "bl.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+------+------+----+--------+----------+---------+-----+-----+-------------+-------------+----+-----+\n",
      "|          timestamp|carrier|flight|origin|dest|wind_dir|wind_speed|wind_gust|visib|force|speed_mi_h_lb|speed_mi_h_ub|name|month|\n",
      "+-------------------+-------+------+------+----+--------+----------+---------+-----+-----+-------------+-------------+----+-----+\n",
      "|2013-01-01 05:17:00|     UA|  1545|   EWR| IAH|    null|      null|     null| null| null|         null|         null|null|    1|\n",
      "|2013-01-01 05:33:00|     UA|  1714|   LGA| IAH|    null|      null|     null| null| null|         null|         null|null|    1|\n",
      "|2013-01-01 05:42:00|     AA|  1141|   JFK| MIA|    null|      null|     null| null| null|         null|         null|null|    1|\n",
      "|2013-01-01 05:44:00|     B6|   725|   JFK| BQN|    null|      null|     null| null| null|         null|         null|null|    1|\n",
      "|2013-01-01 05:54:00|     DL|   461|   LGA| ATL|    null|      null|     null| null| null|         null|         null|null|    1|\n",
      "+-------------------+-------+------+------+----+--------+----------+---------+-----+-----+-------------+-------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_weath_b = \\\n",
    "flights_weath\\\n",
    " .join(bl,\\\n",
    "      flights_weath.wind_speed == bl.speed_mi_h_lb,\\\n",
    "       'left_outer')\\\n",
    " .withColumn('month', month(flights_weath.timestamp)) \n",
    "\n",
    "flights_weath_b.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|month|\n",
      "+-----+\n",
      "|   12|\n",
      "|   11|\n",
      "|   10|\n",
      "|    9|\n",
      "|    8|\n",
      "|    7|\n",
      "|    6|\n",
      "|    5|\n",
      "|    4|\n",
      "|    3|\n",
      "|    2|\n",
      "|    1|\n",
      "| null|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_ord_mnth= flights_weath_b.select('month').distinct().orderBy(desc('month'))\n",
    "\n",
    "distinct_ord_mnth.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_weath_b.write.mode('overwrite').format('csv').save('D:\\\\flights_weath') # creates a folder having part files as data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_weath_b.write.mode('overwrite').parquet('D:\\\\flights_weath_parq') # Saving to Parquet is generally recommended for later retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('timestamp', 'timestamp'),\n",
       " ('carrier', 'string'),\n",
       " ('flight', 'int'),\n",
       " ('origin', 'string'),\n",
       " ('dest', 'string'),\n",
       " ('wind_dir', 'int'),\n",
       " ('wind_speed', 'float'),\n",
       " ('wind_gust', 'float'),\n",
       " ('visib', 'float'),\n",
       " ('force', 'int'),\n",
       " ('speed_mi_h_lb', 'int'),\n",
       " ('speed_mi_h_ub', 'int'),\n",
       " ('name', 'string'),\n",
       " ('month', 'int')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_weath_b.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+------+------+----+--------+--------------+-------------+-----+-----+-------------+-------------+----+-----+--------------+-------------+\n",
      "|          timestamp|carrier|flight|origin|dest|wind_dir|wind_speed_mph|wind_gust_mph|visib|force|speed_mi_h_lb|speed_mi_h_ub|name|month|wind_speed_mps|wind_gust_mps|\n",
      "+-------------------+-------+------+------+----+--------+--------------+-------------+-----+-----+-------------+-------------+----+-----+--------------+-------------+\n",
      "|2013-01-01 05:17:00|     UA|  1545|   EWR| IAH|    null|          null|         null| null| null|         null|         null|null|    1|          null|         null|\n",
      "|2013-01-01 05:33:00|     UA|  1714|   LGA| IAH|    null|          null|         null| null| null|         null|         null|null|    1|          null|         null|\n",
      "|2013-01-01 05:42:00|     AA|  1141|   JFK| MIA|    null|          null|         null| null| null|         null|         null|null|    1|          null|         null|\n",
      "|2013-01-01 05:44:00|     B6|   725|   JFK| BQN|    null|          null|         null| null| null|         null|         null|null|    1|          null|         null|\n",
      "|2013-01-01 05:54:00|     DL|   461|   LGA| ATL|    null|          null|         null| null| null|         null|         null|null|    1|          null|         null|\n",
      "+-------------------+-------+------+------+----+--------+--------------+-------------+-----+-----+-------------+-------------+----+-----+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a function to convert velocity from\n",
    "# miles per hour (mph) to meters per second (mps)\n",
    "\n",
    "def mph_to_mps(mph):\n",
    "    mps = mph * 0.44\n",
    "    return mps\n",
    "\n",
    "# Register this function as a UDF using `udf()`\n",
    "\n",
    "# mph_to_mps = udf(mph_to_mps, FloatType()) # udf(<function name to register>,<return type>)\n",
    "\n",
    "\n",
    "#this is how column of dataframe is passed in func argument if the func is NOT registered using udf\n",
    "\n",
    "flights_weath_b.withColumn('wind_speed_mps', mph_to_mps(col('wind_speed')))\\\n",
    "  .withColumn('wind_gust_mps', mph_to_mps(col('wind_gust')))\\\n",
    "  .withColumnRenamed('wind_speed', 'wind_speed_mph')\\\n",
    "  .withColumnRenamed('wind_gust', 'wind_gust_mph').show(5)\n",
    "\n",
    "#this is how column of dataframe is passed in func argument if the func is registered using udf: (couldn't make it to display dataframe)\n",
    "#more research needed\n",
    "\n",
    "#flights_weath_b\\\n",
    "  #.withColumn('wind_speed_mps', mph_to_mps('wind_speed'))\\\n",
    "  #.withColumn('wind_gust_mps', mph_to_mps('wind_gust'))\\\n",
    "  #.withColumnRenamed('wind_speed', 'wind_speed_mph')\\\n",
    "  #.withColumnRenamed('wind_gust', 'wind_gust_mph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
