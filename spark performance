spark.sql.shuffle.partitions=50/300/any number --specifying number of partitons when shuffling data for joins or aggregations.
spark.default.parallelism=300/any number --specify default number of partitions in RDDs returned by transformations like join, reduceByKey, and parallelize when not set explicitly by the user. 
                                         --Note that spark.default.parallelism seems to only be working for raw RDD and is ignored when working with dataframes.
